{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.15\" 2022-04-19\r\n",
      "OpenJDK Runtime Environment (build 11.0.15+10-Ubuntu-0ubuntu0.20.04.1)\r\n",
      "OpenJDK 64-Bit Server VM (build 11.0.15+10-Ubuntu-0ubuntu0.20.04.1, mixed mode, sharing)\r\n"
     ]
    }
   ],
   "source": [
    "#Setting up the environment\n",
    "\n",
    "!java -version\n",
    "\n",
    "#Install Spark\n",
    "#download file\n",
    "!wget -q http://apache.osuosl.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#extract the file\n",
    "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#install findspark package\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "import os\n",
    "pathToSpark = \"/mnt/c/Users/walid/Desktop/Big Data/Final/spark-3.2.1-bin-hadoop3.2\"\n",
    "os.environ[\"SPARK_HOME\"] = pathToSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf().setAppName(\"FinalProject\").setMaster(\"local[*]\")\n",
    "sc=SparkContext(conf = conf)\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 42.50797080993652 seconds\n"
     ]
    }
   ],
   "source": [
    "# Reading in the directory containing all the JSON files and storing them into\n",
    "# Spark's RDD format\n",
    "\n",
    "import time\n",
    "\n",
    "Filepath = \"/mnt/c/Users/walid/Desktop/Big Data/Final/mpdata/*.json\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df = spark.read.option(\"multiline\", \"true\").json(Filepath)\n",
    "\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "\n",
    "print(\"took \" + str(total_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                info|           playlists|\n",
      "+--------------------+--------------------+\n",
      "|{2017-12-04 03:05...|[{false, null, 82...|\n",
      "|{2017-12-03 08:41...|[{false, null, 10...|\n",
      "|{2017-12-04 03:05...|[{false, null, 16...|\n",
      "|{2017-12-04 03:05...|[{false, null, 39...|\n",
      "|{2017-12-04 03:05...|[{false, null, 82...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- info: struct (nullable = true)\n",
      " |    |-- generated_on: string (nullable = true)\n",
      " |    |-- slice: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- playlists: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- collaborative: string (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- duration_ms: long (nullable = true)\n",
      " |    |    |-- modified_at: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- num_albums: long (nullable = true)\n",
      " |    |    |-- num_artists: long (nullable = true)\n",
      " |    |    |-- num_edits: long (nullable = true)\n",
      " |    |    |-- num_followers: long (nullable = true)\n",
      " |    |    |-- num_tracks: long (nullable = true)\n",
      " |    |    |-- pid: long (nullable = true)\n",
      " |    |    |-- tracks: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- album_name: string (nullable = true)\n",
      " |    |    |    |    |-- album_uri: string (nullable = true)\n",
      " |    |    |    |    |-- artist_name: string (nullable = true)\n",
      " |    |    |    |    |-- artist_uri: string (nullable = true)\n",
      " |    |    |    |    |-- duration_ms: long (nullable = true)\n",
      " |    |    |    |    |-- pos: long (nullable = true)\n",
      " |    |    |    |    |-- track_name: string (nullable = true)\n",
      " |    |    |    |    |-- track_uri: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Taking a look at the schema, we see that all of the headers were successfully imported and \n",
    "# we have all of the data we need to begin analyzing\n",
    "#\n",
    "# The format of the JSON files is deeply nested and so we only have two main columns:\n",
    "# (1) info regarding the slice/part of the json files and when it was generated... info that is useless to us\n",
    "# and (2) a column of playlists, which consists of rows of arrays, meaning each row contains multiple playlists\n",
    "# \n",
    "# We will have to flatten and normalize this dataframe first before we can analyze the data\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           playlists|\n",
      "+--------------------+\n",
      "|{false, null, 824...|\n",
      "|{false, null, 278...|\n",
      "|{false, null, 275...|\n",
      "|{false, null, 178...|\n",
      "|{false, null, 243...|\n",
      "|{false, null, 134...|\n",
      "|{false, null, 523...|\n",
      "|{false, null, 238...|\n",
      "|{false, null, 805...|\n",
      "|{false, null, 279...|\n",
      "|{false, null, 872...|\n",
      "|{false, null, 977...|\n",
      "|{false, really gr...|\n",
      "|{false, null, 293...|\n",
      "|{false, null, 200...|\n",
      "|{false, null, 797...|\n",
      "|{false, null, 865...|\n",
      "|{false, null, 939...|\n",
      "|{false, null, 667...|\n",
      "|{false, null, 434...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "counting # of playlists...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we've removed the useless info column and exploded the array of playlists so that\n",
    "# each playlist was it's own row. \n",
    "#\n",
    "# To double check, we counted the number of rows (1,000,000 playlists)\n",
    "\n",
    "df = df.select(F.explode(F.col(\"playlists\")).alias(\"playlists\"))\n",
    "#df1.printSchema()\n",
    "df.show()\n",
    "print(\"counting # of playlists...\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we take the \"playlists\" column exploded from earlier and select every column to be mapped to its proper header\n",
    "# \n",
    "# We can now work with the playlists data to analyze, calculate, and answer questions.\n",
    "\n",
    "df = df.select(\"playlists.*\") #TODO: change * to only columns that we need to speed up operation times\n",
    "df.show(3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+-----------+\n",
      "|          album_name|   artist_name|          track_name|duration_ms|\n",
      "+--------------------+--------------+--------------------+-----------+\n",
      "|What's up (feat. ...|   Post Malone|What's up (feat. ...|     290533|\n",
      "|     T R A P S O U L| Bryson Tiller|               Don't|     198293|\n",
      "|    Remember My Name|      Lil Durk|             Like Me|     238439|\n",
      "|            Barter 6|    Young Thug|               Check|     230693|\n",
      "|            Barter 6|    Young Thug|With That (feat. ...|     202533|\n",
      "|         Best Friend|    Young Thug|         Best Friend|     213000|\n",
      "|good kid, m.A.A.d...|Kendrick Lamar|  Backseat Freestyle|     212653|\n",
      "|Dreams Worth More...|     Meek Mill|R.I.C.O. (feat. D...|     197133|\n",
      "|           SremmLife|  Rae Sremmurd|             No Type|     200080|\n",
      "|Quarterback (feat...|          Thug|Quarterback (feat...|     301767|\n",
      "+--------------------+--------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66346428"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we isolate the tracks column, which has a lot of information about the tracks nested inside arrays\n",
    "# we explode it and only select the columns that we are interested in looking at...\n",
    "\n",
    "df_tracks = df.select(\"tracks\")\n",
    "df_tracks = df_tracks.select(F.explode(F.col(\"tracks\")).alias(\"tracks\"))\n",
    "df_tracks = df_tracks.select(\"tracks.album_name\", \"tracks.artist_name\", \"tracks.track_name\", \"tracks.duration_ms\")\n",
    "df_tracks.show(10)\n",
    "df_tracks.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|      artist_name| count|\n",
      "+-----------------+------+\n",
      "|            Drake|847160|\n",
      "|       Kanye West|413297|\n",
      "|   Kendrick Lamar|353624|\n",
      "|          Rihanna|339570|\n",
      "|       The Weeknd|316603|\n",
      "|           Eminem|294667|\n",
      "|       Ed Sheeran|272116|\n",
      "|           Future|250734|\n",
      "|    Justin Bieber|243119|\n",
      "|          J. Cole|241560|\n",
      "|          Beyoncé|230857|\n",
      "| The Chainsmokers|223509|\n",
      "|      Chris Brown|212772|\n",
      "|    Calvin Harris|203047|\n",
      "|Twenty One Pilots|198905|\n",
      "|     Lil Uzi Vert|197855|\n",
      "|      Post Malone|195907|\n",
      "|         Big Sean|192478|\n",
      "|         Maroon 5|187029|\n",
      "|            JAY Z|185520|\n",
      "+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Q1: Who were the most popular artists in 2010-2017 in users' playlists?\n",
    "\n",
    "df_tracks.groupBy(\"artist_name\").count().orderBy(['count'], ascending=[False]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----+\n",
      "|          track_name|      artist_name|count|\n",
      "+--------------------+-----------------+-----+\n",
      "|             HUMBLE.|   Kendrick Lamar|46574|\n",
      "|           One Dance|            Drake|43447|\n",
      "|Broccoli (feat. L...|             DRAM|41309|\n",
      "|              Closer| The Chainsmokers|41079|\n",
      "|     Congratulations|      Post Malone|39987|\n",
      "|            Caroline|            Aminé|35202|\n",
      "|iSpy (feat. Lil Y...|             KYLE|35138|\n",
      "|Bad and Boujee (f...|            Migos|34999|\n",
      "|            Location|           Khalid|34990|\n",
      "|       XO TOUR Llif3|     Lil Uzi Vert|34922|\n",
      "|         Bounce Back|         Big Sean|33699|\n",
      "|    Ignition - Remix|         R. Kelly|32391|\n",
      "|      No Role Modelz|          J. Cole|32336|\n",
      "|            Mask Off|           Future|32059|\n",
      "|No Problem (feat....|Chance The Rapper|31492|\n",
      "|         I'm the One|        DJ Khaled|31374|\n",
      "|             Jumpman|            Drake|31119|\n",
      "|          goosebumps|     Travis Scott|31106|\n",
      "|           Fake Love|            Drake|30678|\n",
      "|   Despacito - Remix|       Luis Fonsi|30485|\n",
      "+--------------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: What were the most popular tracks in 2010-2017 in users' playlists?\n",
    "\n",
    "df_tracks.groupBy(\"track_name\", \"artist_name\").count().orderBy(['count'], ascending=[False]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------------+\n",
      "|   Avg Song Duration|Max Song Duration|Min Song Duration|\n",
      "+--------------------+-----------------+-----------------+\n",
      "|1.408938866402694...|    1244674500000|           -60000|\n",
      "+--------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: What is the average song duration? What is the longest song? Shortest?\n",
    "\n",
    "# TODO: convert avg song to mm:ss\n",
    "# TODO: filter -1/0 values from duration_ms\n",
    "# TODO: investigate why max song is so high\n",
    "\n",
    "df_tracks.select((F.avg(\"duration_ms\")*60000).alias(\"Avg Song Duration\"), \\\n",
    "                 (F.max(\"duration_ms\")*60000).alias(\"Max Song Duration\"), \\\n",
    "                 (F.min(\"duration_ms\")*60000).alias(\"Min Song Duration\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playlist Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlists = df.select(\"pid\", \"name\", \"description\", \"num_tracks\", \"num_artists\", \"num_albums\", \"duration_ms\", \"tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     name|count|\n",
      "+---------+-----+\n",
      "|         |70727|\n",
      "|  Country|13280|\n",
      "|    Music|13031|\n",
      "|     Rock|12369|\n",
      "|    music|12356|\n",
      "|   Summer|12298|\n",
      "|    songs|11945|\n",
      "|     2017|11543|\n",
      "|    Chill|10976|\n",
      "|     2016| 9966|\n",
      "| Playlist| 9325|\n",
      "|    Party| 8977|\n",
      "|Christmas| 8678|\n",
      "|    chill| 8392|\n",
      "|  country| 8323|\n",
      "|     Good| 8162|\n",
      "|      New| 8136|\n",
      "|      Rap| 8033|\n",
      "|   summer| 7832|\n",
      "|      The| 7806|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: What is the most common word in the playlist name?\n",
    "\n",
    "df_playlists.withColumn('name', F.explode(F.split(F.col('name'), ' '))) \\\n",
    "  .groupBy('name') \\\n",
    "  .count() \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|description|count|\n",
      "+-----------+-----+\n",
      "|        the| 4501|\n",
      "|         to| 3929|\n",
      "|           | 3386|\n",
      "|        and| 3312|\n",
      "|         of| 3120|\n",
      "|          a| 2523|\n",
      "|        for| 2229|\n",
      "|      songs| 2210|\n",
      "|        you| 2150|\n",
      "|       that| 1598|\n",
      "|         in| 1561|\n",
      "|         my| 1484|\n",
      "|          I| 1391|\n",
      "|   playlist| 1281|\n",
      "|         is| 1279|\n",
      "|       this| 1132|\n",
      "|          i| 1087|\n",
      "|      music| 1066|\n",
      "|       your|  955|\n",
      "|       with|  908|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: What is the most common word in the playlist description?\n",
    "\n",
    "df_playlists.withColumn('description', F.explode(F.split(F.col('description'), ' '))) \\\n",
    "  .groupBy('description') \\\n",
    "  .count() \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   words|count|\n",
      "+--------+-----+\n",
      "|        | 3386|\n",
      "|   songs| 2210|\n",
      "|playlist| 1281|\n",
      "|   music| 1066|\n",
      "|    good|  611|\n",
      "|    love|  547|\n",
      "|  listen|  500|\n",
      "|    best|  469|\n",
      "|   Songs|  429|\n",
      "|    make|  418|\n",
      "|favorite|  376|\n",
      "|     out|  355|\n",
      "|    This|  342|\n",
      "|    feel|  335|\n",
      "|      so|  332|\n",
      "|      up|  329|\n",
      "|   chill|  326|\n",
      "|    will|  324|\n",
      "|       -|  322|\n",
      "|      as|  306|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The most common words are not really useful here in the description,\n",
    "# So some filtering must be done to remove the common word and find common KEY words\n",
    "\n",
    "# TODO: Add more filters or find a way to add values into array and filter by that\n",
    "\n",
    "pl_clean_description = df_playlists.withColumn('words', F.explode(F.split(F.col('description'), ' '))) \\\n",
    "  .groupBy('words') \\\n",
    "  .count() \\\n",
    "  .filter((F.col(\"words\") != \"the\") & (F.col(\"words\") != \"to\") & (F.col(\"words\") != \" \") & (F.col(\"words\") != \"and\") &\\\n",
    "          (F.col(\"words\") != \"of\") & (F.col(\"words\") != \"a\") & (F.col(\"words\") != \"for\") & (F.col(\"words\") != \"you\") &\\\n",
    "          (F.col(\"words\") != \"that\") & (F.col(\"words\") != \"in\") & (F.col(\"words\") != \"my\") & (F.col(\"words\") != \"I\") &\\\n",
    "          (F.col(\"words\") != \"is\") & (F.col(\"words\") != \"this\") & (F.col(\"words\") != \"i\") & (F.col(\"words\") != \"your\")&\\\n",
    "          (F.col(\"words\") != \"with\") & (F.col(\"words\") != \"from\") & (F.col(\"words\") != \"all\") & (F.col(\"words\") != \"me\")&\\\n",
    "          (F.col(\"words\") != \"some\") & (F.col(\"words\") != \"on\") & (F.col(\"words\") != \"when\") & (F.col(\"words\") != \"it\")&\\\n",
    "          (F.col(\"words\") != \"just\") & (F.col(\"words\") != \"like\") & (F.col(\"words\") != \"are\") & (F.col(\"words\") != \"or\")&\\\n",
    "          (F.col(\"words\") != \"The\") & (F.col(\"words\") != \"be\") & (F.col(\"words\") != \" \") & (F.col(\"words\") != \"A\")&\\\n",
    "          (F.col(\"words\") != \"have\") & (F.col(\"words\") != \"at\") & (F.col(\"words\") != \"these\") & (F.col(\"words\") != \"I\") &\\\n",
    "          (F.col(\"words\") != \"that\") & (F.col(\"words\") != \"in\") & (F.col(\"words\") != \"my\") & (F.col(\"words\") != \"I\") &\\\n",
    "          (F.col(\"words\") != \"but\") & (F.col(\"words\") != \"get\") & (F.col(\"words\") != \"by\") & (F.col(\"words\") != \"not\")) \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  \n",
    "pl_clean_description.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_genres = {\"pop\", \"rock\", \"hip hop\", \"latin\", \"dance\", \"edm\", \"r&b\", \"country\", \"classical\", \"metal\", \"jazz\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+---------------------+\n",
      "|Avg Playlist Duration|Max Playlist Duration|Min Playlist Duration|\n",
      "+---------------------+---------------------+---------------------+\n",
      "|   9.3478061056188E11|       38104427520000|           5852280000|\n",
      "+---------------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: What is the average playlist duration? Is there a maximum duration to a playlist? min?\n",
    "\n",
    "df_playlists.select((F.avg(\"duration_ms\")*60000).alias(\"Avg Playlist Duration\"), \\\n",
    "                    (F.max(\"duration_ms\")*60000).alias(\"Max Playlist Duration\"), \\\n",
    "                    (F.min(\"duration_ms\")*60000).alias(\"Min Playlist Duration\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|Avg Number of Tracks|Max Number of Tracks|Min Number of Tracks|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|           66.346428|                 376|                   5|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q4: What is the average playlist track number? Is there a maximum amount of tracks to a playlist? min?\n",
    "\n",
    "df_playlists.select((F.avg(\"num_tracks\")).alias(\"Avg Number of Tracks\"), \\\n",
    "                    (F.max(\"num_tracks\")).alias(\"Max Number of Tracks\"), \\\n",
    "                    (F.min(\"num_tracks\")).alias(\"Min Number of Tracks\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
