{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.15\" 2022-04-19\r\n",
      "OpenJDK Runtime Environment (build 11.0.15+10-Ubuntu-0ubuntu0.20.04.1)\r\n",
      "OpenJDK 64-Bit Server VM (build 11.0.15+10-Ubuntu-0ubuntu0.20.04.1, mixed mode, sharing)\r\n"
     ]
    }
   ],
   "source": [
    "#Setting up the environment\n",
    "\n",
    "!java -version\n",
    "\n",
    "#Install Spark\n",
    "#download file\n",
    "!wget -q http://apache.osuosl.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#extract the file\n",
    "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#install findspark package\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "import os\n",
    "pathToSpark = \"/mnt/c/Users/walid/Desktop/Big Data/Final/spark-3.2.1-bin-hadoop3.2\"\n",
    "os.environ[\"SPARK_HOME\"] = pathToSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf().setAppName(\"FinalProject\").setMaster(\"local[*]\")\n",
    "sc=SparkContext(conf = conf)\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 35.14468455314636 seconds\n"
     ]
    }
   ],
   "source": [
    "# Reading in the directory containing all the JSON files and storing them into\n",
    "# Spark's RDD format\n",
    "\n",
    "import time\n",
    "\n",
    "Filepath = \"/mnt/c/Users/walid/Desktop/Big Data/Final/mpdata/*.json\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df = spark.read.option(\"multiline\", \"true\").json(Filepath)\n",
    "\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "\n",
    "print(\"took \" + str(total_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                info|           playlists|\n",
      "+--------------------+--------------------+\n",
      "|{2017-12-04 03:05...|[{false, null, 82...|\n",
      "|{2017-12-03 08:41...|[{false, null, 10...|\n",
      "|{2017-12-04 03:05...|[{false, null, 16...|\n",
      "|{2017-12-04 03:05...|[{false, null, 39...|\n",
      "|{2017-12-04 03:05...|[{false, null, 82...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- info: struct (nullable = true)\n",
      " |    |-- generated_on: string (nullable = true)\n",
      " |    |-- slice: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- playlists: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- collaborative: string (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- duration_ms: long (nullable = true)\n",
      " |    |    |-- modified_at: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- num_albums: long (nullable = true)\n",
      " |    |    |-- num_artists: long (nullable = true)\n",
      " |    |    |-- num_edits: long (nullable = true)\n",
      " |    |    |-- num_followers: long (nullable = true)\n",
      " |    |    |-- num_tracks: long (nullable = true)\n",
      " |    |    |-- pid: long (nullable = true)\n",
      " |    |    |-- tracks: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- album_name: string (nullable = true)\n",
      " |    |    |    |    |-- album_uri: string (nullable = true)\n",
      " |    |    |    |    |-- artist_name: string (nullable = true)\n",
      " |    |    |    |    |-- artist_uri: string (nullable = true)\n",
      " |    |    |    |    |-- duration_ms: long (nullable = true)\n",
      " |    |    |    |    |-- pos: long (nullable = true)\n",
      " |    |    |    |    |-- track_name: string (nullable = true)\n",
      " |    |    |    |    |-- track_uri: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Taking a look at the schema, we see that all of the headers were successfully imported and \n",
    "# we have all of the data we need to begin analyzing\n",
    "#\n",
    "# The format of the JSON files is deeply nested and so we only have two main columns:\n",
    "# (1) info regarding the slice/part of the json files and when it was generated... info that is useless to us\n",
    "# and (2) a column of playlists, which consists of rows of arrays, meaning each row contains multiple playlists\n",
    "# \n",
    "# We will have to flatten and normalize this dataframe first before we can analyze the data\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           playlists|\n",
      "+--------------------+\n",
      "|{false, null, 824...|\n",
      "|{false, null, 278...|\n",
      "|{false, null, 275...|\n",
      "|{false, null, 178...|\n",
      "|{false, null, 243...|\n",
      "|{false, null, 134...|\n",
      "|{false, null, 523...|\n",
      "|{false, null, 238...|\n",
      "|{false, null, 805...|\n",
      "|{false, null, 279...|\n",
      "|{false, null, 872...|\n",
      "|{false, null, 977...|\n",
      "|{false, really gr...|\n",
      "|{false, null, 293...|\n",
      "|{false, null, 200...|\n",
      "|{false, null, 797...|\n",
      "|{false, null, 865...|\n",
      "|{false, null, 939...|\n",
      "|{false, null, 667...|\n",
      "|{false, null, 434...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "counting # of playlists...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we've removed the useless info column and exploded the array of playlists so that\n",
    "# each playlist was it's own row. \n",
    "#\n",
    "# To double check, we counted the number of rows (1,000,000 playlists)\n",
    "\n",
    "df = df.select(F.explode(F.col(\"playlists\")).alias(\"playlists\"))\n",
    "#df1.printSchema()\n",
    "df.show()\n",
    "print(\"counting # of playlists...\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+-----------+----------+----------+-----------+---------+-------------+----------+------+--------------------+\n",
      "|collaborative|description|duration_ms|modified_at|      name|num_albums|num_artists|num_edits|num_followers|num_tracks|   pid|              tracks|\n",
      "+-------------+-----------+-----------+-----------+----------+----------+-----------+---------+-------------+----------+------+--------------------+\n",
      "|        false|       null|    8247098| 1502928000|      pump|        32|         27|       23|            2|        36|834000|[{What's up (feat...|\n",
      "|        false|       null|   27861520| 1472860800| Summer 16|        89|         75|        5|            2|       117|834001|[{And Star Power,...|\n",
      "|        false|       null|   27577113| 1507075200|old school|        95|         65|       18|            2|       126|834002|[{Up All Night, s...|\n",
      "+-------------+-----------+-----------+-----------+----------+----------+-----------+---------+-------------+----------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- collaborative: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- duration_ms: long (nullable = true)\n",
      " |-- modified_at: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_albums: long (nullable = true)\n",
      " |-- num_artists: long (nullable = true)\n",
      " |-- num_edits: long (nullable = true)\n",
      " |-- num_followers: long (nullable = true)\n",
      " |-- num_tracks: long (nullable = true)\n",
      " |-- pid: long (nullable = true)\n",
      " |-- tracks: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- album_name: string (nullable = true)\n",
      " |    |    |-- album_uri: string (nullable = true)\n",
      " |    |    |-- artist_name: string (nullable = true)\n",
      " |    |    |-- artist_uri: string (nullable = true)\n",
      " |    |    |-- duration_ms: long (nullable = true)\n",
      " |    |    |-- pos: long (nullable = true)\n",
      " |    |    |-- track_name: string (nullable = true)\n",
      " |    |    |-- track_uri: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we take the \"playlists\" column exploded from earlier and select every column to be mapped to its proper header\n",
    "# \n",
    "# We can now work with the playlists data to analyze, calculate, and answer questions.\n",
    "\n",
    "df = df.select(\"playlists.*\") #TODO: change * to only columns that we need to speed up operation times\n",
    "df.show(3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+-----------+\n",
      "|          album_name|   artist_name|          track_name|duration_ms|\n",
      "+--------------------+--------------+--------------------+-----------+\n",
      "|What's up (feat. ...|   Post Malone|What's up (feat. ...|     290533|\n",
      "|     T R A P S O U L| Bryson Tiller|               Don't|     198293|\n",
      "|    Remember My Name|      Lil Durk|             Like Me|     238439|\n",
      "|            Barter 6|    Young Thug|               Check|     230693|\n",
      "|            Barter 6|    Young Thug|With That (feat. ...|     202533|\n",
      "|         Best Friend|    Young Thug|         Best Friend|     213000|\n",
      "|good kid, m.A.A.d...|Kendrick Lamar|  Backseat Freestyle|     212653|\n",
      "|Dreams Worth More...|     Meek Mill|R.I.C.O. (feat. D...|     197133|\n",
      "|           SremmLife|  Rae Sremmurd|             No Type|     200080|\n",
      "|Quarterback (feat...|          Thug|Quarterback (feat...|     301767|\n",
      "+--------------------+--------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66346428"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we isolate the tracks column, which has a lot of information about the tracks nested inside arrays\n",
    "# we explode it and only select the columns that we are interested in looking at...\n",
    "\n",
    "\n",
    "df_tracks = df.select(\"tracks\")\n",
    "df_tracks = df_tracks.select(F.explode(F.col(\"tracks\")).alias(\"tracks\"))\n",
    "df_tracks = df_tracks.select(\"tracks.album_name\", \"tracks.artist_name\", \"tracks.track_name\", \"tracks.duration_ms\")\n",
    "df_tracks.show(10)\n",
    "df_tracks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
